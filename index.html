---
layout: default
pagination:
enabled: true
---
<!-- Place this tag in your head or just before your close body tag. -->
<script async defer src="https://buttons.github.io/buttons.js"></script>

<div class="home">

  <div class="site-header-container {% if site.cover %}has-cover{% endif %}"
    {% if site.cover %}style="background-image: url({{ site.cover | prepend: site.baseurl }});" {% endif %}>
    <div class="scrim {% if site.cover %}has-cover{% endif %}">
      <header class="site-header">
        <h1 class="title" style=font-size:80px>{{ site.title }}</h1>
        {% if site.subtitle %}<p class="title" style=font-size:30px>{{ site.subtitle }}</p>{% endif %}
      </header>
    </div>
  </div>

  <div class="wrapper">
    <h1 id="headings">Introduction</h1>
    <p style="text-align: justify">
      Autonomous car racing is a major challenge in robotics.
      It raises fundamental problems for classical approaches such as planning minimum-time trajectories under uncertain
      dynamics and controlling the car at its limits of handling.
      Besides, the requirement of minimizing the lap time, which is a sparse objective, and the difficulty of collecting
      training data from human experts have also hindered researchers from directly applying learning-based approaches
      to solve the problem.
      In the present work, we propose a learning-based system for autonomous car racing by leveraging high-fidelity
      physical car simulation, novel course-progress-proxy reward design, and deep reinforcement learning.
      We deploy our system in Gran Turismo Sport, a world-leading car simulator known for its advanced
      graphics design and very realistic physics simulation of different race cars and tracks, which is even used to
      recruit human race car drivers.
      Our trained policy achieves autonomous racing performance that goes beyond what
      had been achieved so far by the built-in AI, and, at the same time, outperforms
      the fastest driver in a dataset of over 50,000 human players.
    </p>

    <h2 id="headings">Video</h2>
    <iframe width="750" height="421" src="https://www.youtube.com/embed/Zeyv1bN9v4A" frameborder="0"
      allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
      allowfullscreen></iframe>

  </div>
</div>

<div class="home">
  <div class="site-header-container {% if site.cover1 %}has-cover{% endif %}"
    {% if site.cover1 %}style="background-image: url({{ site.cover1 | prepend: site.baseurl }});" {% endif %}>
    <div class="scrim {% if site.cover1 %}has-cover{% endif %}">
      <header class="site-header">
        <h1 class="title" style=font-size:80px>{{ site.title1 }}</h1>
        {% if site.subtitle1 %}<p class="title" style=font-size:30px>{{ site.subtitle1 }}</p>{% endif %}
      </header>
    </div>
  </div>
  <div class="wrapper">
    <h1 id="headings">Introduction</h1>
    <p style="text-align: justify">
      Autonomous overtaking is a long-standing problem in car racing, where the goal is to overtake opponents
      as fast as possible, while at the same time avoiding collisions.
      Human car racers first learn how to drive as fast as they can and only then learn how to overtake their opponents.
      Can we use the same training principle for developing intelligent autonomous racing systems?
      In this work, we tackle the overtaking problem
      in autonomous car racing using curriculum reinforcement
      learning.
      We start by training a neural network policy for autonomous racing in a single-car time trial setting.
      Then, we progressively train the same neural network for overtaking.
      We show that this training methodology leads to faster convergence as well as increased performance compared to
      learning from scratch.
      We evaluate our approach in Gran Turismo Sport---a world-leading car-racing simulator known for its detailed
      dynamics modeling
      of various cars and tracks.
      We show that our trained policy outperforms the built-in game AI and achieves comparable overtaking performance as
      an experienced human player.
      We use an objective evaluation metric to benchmark the
      overtaking performance and demonstrate that our agent can
      perform aggressive overtaking trajectories in a highly
      dynamic racing environment.
    </p>

    <h2 id="headings">Video</h2>
    Coming Soon

  </div>
</div>
<!-- <div class="container" style="margin-top:30px;margin-bottom:30px;">
      <h2>Reference</h2>
      If you use this code in a publication, please cite our paper.
      <div class="row">

        <div class="col-lg-4" style="padding:0;">
          <a href="https://arxiv.org/abs/2009.00563">
            <img style="width: 300px" src="assets/paper_thumbnail.png" alt="Flightmare: A Flexible Quadrotor Simulator">
          </a>
        </div>

        <div class="col-lg-8" style="padding:0;">
          <div style="background:#ffffff;margin:0px;padding:0px;">
            <pre>
          <code class="pre-scrollable" style="background:#ffffff;color:#333;font-size:12px;padding:0px;border-width:0px;">
            @article{yunlong2020flightmare,
            title={Flightmare: A Flexible Quadrotor Simulator},
            author={Song, Yunlong and Naji, Selim and Kaufmann, Elia and Loquercio, Antonio and Scaramuzza, Davide},
            journal={arXiv preprint arXiv:2009.00563},
            year={2020}}
          </code>
          </pre>
          </div>
        </div>
      </div>
    </div> -->